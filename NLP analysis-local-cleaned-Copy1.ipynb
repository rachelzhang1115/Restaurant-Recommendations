{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize, WhitespaceTokenizer\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from rake_nltk import Rake\n",
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('restaurant_reviews.json', 'r') as f:\n",
    "     data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223447"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of reviews#\n",
    "totalreview=0\n",
    "for i in data:\n",
    "    totalreview+=int(i['reviews-total-number'])\n",
    "totalreview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##add in the urls for each restaurant\n",
    "import csv\n",
    "with open('restaurant_url.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    restaurant_url = list(reader)\n",
    "    \n",
    "restaurant_url.remove(restaurant_url[0])\n",
    "restaurant_url = [y for x in restaurant_url for y in x]\n",
    "\n",
    "for i in range(0,50):\n",
    "    data[i]['url']=restaurant_url[241+i]\n",
    "    \n",
    "for i in range(50,len(data)):\n",
    "    data[i]['url']=restaurant_url[i-50]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_word=stopwords.words('english')\n",
    "stop_word.extend(['restaurant', 'outdoor', 'indoor', 'seating', 'happy hour', 'happy hours','opening','call',\n",
    "                 'minutes','minute','hour','hours'])\n",
    "\n",
    "#open the original_food list for the search of food names\n",
    "with open('foodlist copy.txt','r') as f:\n",
    "    l = f.readlines()\n",
    "original_food = []\n",
    "for i in l:\n",
    "    original_food.append(i.replace('\\n', '').lower())\n",
    "\n",
    "    \n",
    "#Calculating the lower bound wilson score for each restaurant based on \n",
    "#total reviews, and #total positive reviews\n",
    "    \n",
    "def confidence(total_positive, total):\n",
    "    n = total\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    z = 1.96 #95% CI\n",
    "    phat = total_positive / n\n",
    "    return ((phat + z*z/(2*n) - z * sqrt((phat*(1-phat)+z*z/(4*n))/n))/(1+z*z/n))\n",
    "\n",
    "#analyze each restaurant  \n",
    "restaurants_dish=[]\n",
    "for k in data:\n",
    "    #clean up the text_review on single restaurant basis\n",
    "    rest_review=k['text_review']\n",
    "    rest_review=[i.replace('<p lang=\"en\">', '').replace('<br/><br/>', '').replace('</p>', '')\n",
    "                 for i in rest_review]\n",
    "    rest_review=[re.sub(r'<.*>', '',i) for i in rest_review]\n",
    "    \n",
    "    #sentiment for each review\n",
    "    review_sentiment=[]\n",
    "    for review in rest_review:\n",
    "        blob = TextBlob(review)\n",
    "        #keep the polarity only\n",
    "        review_sentiment.append(blob.sentiment[0])\n",
    "    \n",
    "    #Calculating the lower bound wilson score for each restaurant\n",
    "    total_positive=sum([True for i in review_sentiment if i>=0])\n",
    "    total=len(review_sentiment)\n",
    "    wilson_CI=confidence(total_positive, total)\n",
    "    \n",
    "    \n",
    "    # Create a CountVectorizer for the original reviews, without parsing out the keywords\n",
    "    cv = CountVectorizer(ngram_range=(2, 3),stop_words=stop_word, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "    rest_review_vecs=cv.fit_transform(rest_review)\n",
    "    #count the number of mentions of each word phrase\n",
    "    #rest_review_vecs_sentiment=(rest_review_vecs.T.multiply(np.array(review_sentiment))).T\n",
    "    word_counts=list(zip(cv.get_feature_names(),rest_review_vecs.sum(axis=0).tolist()[0]))\n",
    "    word_counts_sorted=sorted(word_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #search for food items in the top mentioned word phrases\n",
    "    mentioned_food=[]\n",
    "    for i in original_food:\n",
    "        sub=i\n",
    "        mentioned_food.append([s for s in word_counts_sorted[0:10] if sub in s[0]])\n",
    "        mentioned_food=[x for x in mentioned_food if x != []]\n",
    "    \n",
    "    recommend_list=set(sum(mentioned_food, []))\n",
    "    recommend_list=sorted(recommend_list, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "    restaurant_dish={}\n",
    "    restaurant_dish['Name']=k['name']\n",
    "    restaurant_dish['Total Number of Reviews']=k['reviews-total-number']\n",
    "    restaurant_dish['Overall Rating']=k['overall-rating']\n",
    "    restaurant_dish['Wilson Score']=wilson_CI\n",
    "    restaurant_dish['Restaurant Link']=k['url']\n",
    "    restaurant_dish['Recommended Dish']=recommend_list\n",
    "    \n",
    "    restaurants_dish.append(restaurant_dish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#store final results in json file for html to use\n",
    "# with open('restaurants_dish.json', 'w') as f:\n",
    "#      json.dump(restaurants_dish, f)\n",
    "        \n",
    "with open('restaurants_dish.json', 'r') as f:\n",
    "     restaurants_dish = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('restaurants_dish.json', 'r') as f:\n",
    "     restaurants_dish = json.load(f)\n",
    "len(restaurants_dish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hogwash',\n",
       "  \"Yelp's Rating: 4.5\",\n",
       "  \"Rachel's Rating: 94\",\n",
       "  ['fried pickles:135 mentions',\n",
       "   'curry fries:124 mentions',\n",
       "   'beer selection:119 mentions',\n",
       "   'great beer:53 mentions',\n",
       "   'sausage sandwich:50 mentions',\n",
       "   'duck egg:49 mentions',\n",
       "   'beers tap:38 mentions'],\n",
       "  'https://www.yelp.com/biz/hogwash-san-francisco?osq=Restaurants'],\n",
       " ['The Dark Horse Inn',\n",
       "  \"Yelp's Rating: 4.5\",\n",
       "  \"Rachel's Rating: 94\",\n",
       "  ['beer selection:57 mentions',\n",
       "   'pulled pork:49 mentions',\n",
       "   'mac cheese:43 mentions',\n",
       "   'fried pickles:28 mentions',\n",
       "   'fish tacos:22 mentions'],\n",
       "  'https://www.yelp.com/biz/the-dark-horse-inn-san-francisco?osq=Restaurants'],\n",
       " ['Mikkeller Bar',\n",
       "  \"Yelp's Rating: 4.0\",\n",
       "  \"Rachel's Rating: 93\",\n",
       "  ['beer selection:155 mentions',\n",
       "   'great beer:56 mentions',\n",
       "   'beers tap:54 mentions',\n",
       "   'beer list:52 mentions',\n",
       "   'mac cheese:49 mentions',\n",
       "   'craft beer:46 mentions'],\n",
       "  'https://www.yelp.com/biz/mikkeller-bar-san-francisco?osq=Restaurants'],\n",
       " ['Fermentation Lab',\n",
       "  \"Yelp's Rating: 4.5\",\n",
       "  \"Rachel's Rating: 92\",\n",
       "  ['chicken sandwich:12 mentions',\n",
       "   'beer selection:11 mentions',\n",
       "   'great beer:8 mentions',\n",
       "   'deviled eggs:8 mentions',\n",
       "   'beers tap:5 mentions',\n",
       "   'beer list:5 mentions'],\n",
       "  'https://www.yelp.com/biz/fermentation-lab-san-francisco?osq=Restaurants'],\n",
       " ['Barrel Head Brewhouse',\n",
       "  \"Yelp's Rating: 4.0\",\n",
       "  \"Rachel's Rating: 89\",\n",
       "  ['beer selection:37 mentions',\n",
       "   'great beer:25 mentions',\n",
       "   'fish chips:23 mentions'],\n",
       "  'https://www.yelp.com/biz/barrel-head-brewhouse-san-francisco-5?osq=Restaurants'],\n",
       " ['Buffalo Theory',\n",
       "  \"Yelp's Rating: 4.0\",\n",
       "  \"Rachel's Rating: 88\",\n",
       "  ['beer selection:25 mentions',\n",
       "   'adobo wings:20 mentions',\n",
       "   'chicken wings:17 mentions',\n",
       "   'chicken katsu:15 mentions',\n",
       "   'pork belly:15 mentions',\n",
       "   'sisig grits:15 mentions',\n",
       "   'sticky rice:15 mentions'],\n",
       "  'https://www.yelp.com/biz/buffalo-theory-san-francisco-2?osq=Restaurants'],\n",
       " ['Woodbury',\n",
       "  \"Yelp's Rating: 4.0\",\n",
       "  \"Rachel's Rating: 87\",\n",
       "  ['beer shot:11 mentions', 'chili cheese:10 mentions'],\n",
       "  'https://www.yelp.com/biz/woodbury-san-francisco?osq=Restaurants'],\n",
       " ['Zen Izakaya',\n",
       "  \"Yelp's Rating: 4.0\",\n",
       "  \"Rachel's Rating: 86\",\n",
       "  ['wagyu beef:13 mentions',\n",
       "   'ice cream:6 mentions',\n",
       "   'sushi rolls:6 mentions',\n",
       "   'free beer:5 mentions',\n",
       "   'miso soup:5 mentions'],\n",
       "  'https://www.yelp.com/biz/zen-izakaya-san-francisco-3?osq=Restaurants'],\n",
       " ['Sessions at the Presidio',\n",
       "  \"Yelp's Rating: 3.5\",\n",
       "  \"Rachel's Rating: 84\",\n",
       "  ['cheese dumplings:30 mentions',\n",
       "   'fried chicken:18 mentions',\n",
       "   'beer list:17 mentions',\n",
       "   'beer selection:14 mentions',\n",
       "   'fish tacos:13 mentions'],\n",
       "  'https://www.yelp.com/biz/sessions-at-the-presidio-san-francisco?osq=Restaurants'],\n",
       " ['Trademark & Copyright',\n",
       "  \"Yelp's Rating: 4.5\",\n",
       "  \"Rachel's Rating: 72\",\n",
       "  ['ice cream:8 mentions',\n",
       "   'bacon wrapped mochi:5 mentions',\n",
       "   'bacon wrapped:5 mentions',\n",
       "   'beer pong:4 mentions'],\n",
       "  'https://www.yelp.com/biz/trademark-and-copyright-san-francisco?osq=Restaurants']]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###code for flask app###\n",
    "#when customer input a dish name, returns a list of restaurants ordered by their wilson score\n",
    "recommended_restaurants=[]\n",
    "for i in restaurants_dish:\n",
    "    recommended_restaurants.append(list(set([(i['Name'], i['Overall Rating'],i['Total Number of Reviews'],float(i['Wilson Score']), i['Restaurant Link']) for s in i['Recommended Dish'] \n",
    "                                    if 'beer' in s[0]])))\n",
    "recommended_restaurants=sum([x for x in recommended_restaurants if x != []], [])                                                                    \n",
    "recommended_restaurants=sorted(recommended_restaurants, key=lambda x: x[-2], reverse=True) \n",
    "\n",
    "recommended_restaurants_formatted=[]\n",
    "for i in recommended_restaurants:\n",
    "    recommended_restaurants_formatted.append([i[0], \"Yelp's Rating\"+': '+  i[1],\"Rachel's Rating\"+': ' + str(round((i[-2])*100)),\n",
    "                                              [s['Recommended Dish'] for s in restaurants_dish if i[0] in s['Name']][0],i[-1] ])\n",
    "for i in recommended_restaurants_formatted:\n",
    "    i[3]=[j[0]+':' +str(j[1])+' mentions' for j in i[3]]\n",
    "\n",
    "recommended_restaurants_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment score for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_sentiment=[]\n",
    "for review in rest_review:\n",
    "    blob = TextBlob(review)\n",
    "    #keep the polarity only\n",
    "    review_sentiment.append(blob.sentiment[0])\n",
    "#review_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combining word_vectors and count vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_word=stopwords.words('english')\n",
    "stop_word.extend(['restaurant', 'outdoor', 'indoor', 'seating', 'happy hour', 'happy hours','opening','call'])\n",
    "\n",
    "#open the original_food list for the search of food names\n",
    "with open('foodlist copy.txt','r') as f:\n",
    "    l = f.readlines()\n",
    "original_food = []\n",
    "for i in l:\n",
    "    original_food.append(i.replace('\\n', '').lower())\n",
    "    \n",
    "#analyze each restaurant  \n",
    "restaurants_dish=[]\n",
    "for k in data[0:1]:\n",
    "    #clean up the text_review on single restaurant basis\n",
    "    rest_review=k['text_review']\n",
    "    rest_review=[i.replace('<p lang=\"en\">', '').replace('<br/><br/>', '').replace('</p>', '')\n",
    "                 for i in rest_review]\n",
    "    rest_review=[re.sub(r'<.*>', '',i) for i in rest_review]\n",
    "    \n",
    "    # Create a CountVectorizer for the original reviews, without parsing out the keywords\n",
    "    cv = CountVectorizer(ngram_range=(2, 3),stop_words=stop_word, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "    rest_review_vecs=cv.fit_transform(rest_review)\n",
    "    rest_review_df=pd.DataFrame(rest_review_vecs.todense(), columns=[cv.get_feature_names()])\n",
    "    #count the number of mentions of each word phrase\n",
    "    word_counts = list(zip(rest_review_df.columns, rest_review_df.sum(axis=0)))\n",
    "    word_counts_sorted=sorted(word_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #search for food items in the top mentioned word phrases\n",
    "    mentioned_food=[]\n",
    "    for i in original_food:\n",
    "        sub=i\n",
    "        mentioned_food.append([s for s in word_counts_sorted[0:10] if sub in s[0]])\n",
    "        mentioned_food=[x for x in mentioned_food if x != []]\n",
    "    \n",
    "    recommend_list=set(sum(mentioned_food, []))\n",
    "    recommend_list=sorted(recommend_list, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    ## Dimension Reduction, feature extraction \n",
    "    lsa = TruncatedSVD(50, algorithm = 'arpack')\n",
    "    reduced_mat = lsa.fit_transform(rest_review_vecs)\n",
    "    reduced_mat = Normalizer(copy=False).fit_transform(reduced_mat)\n",
    "    word_vecs=lsa.components_\n",
    "\n",
    "\n",
    "    ##Find similar words based on vectors\n",
    "    def get_similar_docs(target_vec, corpus_vecs, num_res=5):\n",
    "        sim_scores = np.dot(target_vec.T, corpus_vecs)\n",
    "        return np.argsort(-sim_scores)[:num_res]\n",
    "\n",
    "    index1=rest_review_df.columns.get_loc(recommend_list[0][0])\n",
    "    similar_index1=get_similar_docs(word_vecs[:, index1],word_vecs)\n",
    "    similar_dish_list=[]\n",
    "    for i in similar_index1:\n",
    "        similar_dish_list.append(rest_review_df.columns[i])\n",
    "\n",
    "\n",
    "    \n",
    "    #combine word_vec similar dish and the top counted similar dish\n",
    "    recommended_dish=set(similar_dish_list+recommend_list)\n",
    "\n",
    "    restaurant_dish={}\n",
    "    restaurant_dish['name']=k['name']\n",
    "    restaurant_dish['reviews-total-number']=k['reviews-total-number']\n",
    "    restaurant_dish['overall-rating']=k['overall-rating']\n",
    "    restaurant_dish['recommended_dish']=recommended_dish\n",
    "    \n",
    "    restaurants_dish.append(restaurant_dish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Barrel Head Brewhouse',\n",
       " 'overall-rating': '4.0',\n",
       " 'recommended_dish': {('fish chips', 23),\n",
       "  'seems like',\n",
       "  'happy hour',\n",
       "  'great beer',\n",
       "  'beer selection',\n",
       "  ('beer selection', 37),\n",
       "  ('great beer', 25),\n",
       "  'food great'},\n",
       " 'reviews-total-number': 427}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_dish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Stanford Core NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Text with some entities\n",
    "# ner_text = rest_review[0]\n",
    "\n",
    "# # Create Tokens\n",
    "# tokens = pos_tag(word_tokenize(ner_text))\n",
    "\n",
    "# # Extract entities from token list\n",
    "# entities = ne_chunk(tokens)\n",
    "# print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "# res = nlp.annotate(rest_review[1],\n",
    "#                    properties={\n",
    "#                        'annotators': 'sentiment',\n",
    "#                        'outputFormat': 'json',\n",
    "#                        'timeout': 2000,\n",
    "#                    })\n",
    "\n",
    "# for s in res[\"sentences\"]:\n",
    "#     print (s[\"index\"],\n",
    "#         \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "#          s[\"sentimentValue\"], s[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res = nlp.annotate(rest_review[1],\n",
    "#                    properties={\n",
    "#                        'annotators': 'ner',\n",
    "#                        'outputFormat': 'json',\n",
    "#                        'timeout': 2000,\n",
    "#                    })\n",
    "# res\n",
    "# # for s in res[\"sentences\"]:\n",
    "# #     print (s[\"index\"],\n",
    "# #         \" \".join([t[\"word\"] for t in s[\"tokens\"]]),\n",
    "# #              s[\"NN\"], s[\"NNS\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
